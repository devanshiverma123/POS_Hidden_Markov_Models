{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3d67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2480da",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ebd3c",
   "metadata": {},
   "source": [
    "``` In this part I have generated the word vocab. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "348c13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/train\", \"r\")\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff75458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3f1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the frequency dictionary for all the words.\n",
    "\n",
    "complete_data = data.split('\\n')\n",
    "total_sentences = 0\n",
    "\n",
    "for index in range(len(complete_data)):\n",
    "    each_token = complete_data[index].split('\\t')\n",
    "\n",
    "    if each_token[0] != '':\n",
    "        if each_token[1] not in word_vocab:\n",
    "            word_vocab[each_token[1]] = 1\n",
    "        else:\n",
    "            word_vocab[each_token[1]] += 1\n",
    "    else:\n",
    "        total_sentences += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d65db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange all the word according to decreasing order of frequency.\n",
    "\n",
    "word_vocab_ordered = OrderedDict()\n",
    "word_vocab_ordered['<unk>'] = 0\n",
    "for w in sorted(word_vocab, key = word_vocab.get, reverse = True):\n",
    "    if word_vocab[w] <= 1:\n",
    "        word_vocab_ordered['<unk>'] += 1\n",
    "    else:\n",
    "        word_vocab_ordered[w] = word_vocab[w] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97267aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Vocab Size: 23183\n"
     ]
    }
   ],
   "source": [
    "print(\"Word Vocab Size:\", len(word_vocab_ordered) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973ce3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the desired output format.\n",
    "index = 0\n",
    "result = \"\"\n",
    "for k, v in word_vocab_ordered.items():\n",
    "    result+= k + \"\\t\" + str(index) + \"\\t\" + str(v) + \"\\n\"\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e63c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.txt\", \"w\") as text_file:\n",
    "    text_file.write(format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d256f",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201556d2",
   "metadata": {},
   "source": [
    "``` This task includes the generation of transition, emission and start probabilities.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1d6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_result = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9be14bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagging_dict = OrderedDict()\n",
    "\n",
    "start_state_dict = OrderedDict()\n",
    "start_state_dict[complete_data[0].split('\\t')[2]] = 1\n",
    "\n",
    "sentence_start = 0\n",
    "for index in range(len(complete_data)):\n",
    "    each_token = complete_data[index].split('\\t')\n",
    "    if each_token[0] != '':\n",
    "        if sentence_start == 1:\n",
    "            start_state_dict[each_token[2]] = start_state_dict.get(each_token[2], 0) + 1\n",
    "            sentence_start = 0\n",
    "\n",
    "        pos_tagging_dict[each_token[2]] =  pos_tagging_dict.get(each_token[2], 0) + 1\n",
    "    else:\n",
    "        sentence_start = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754f30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the starting probabilites for all the tags with which the sentence begins.\n",
    "\n",
    "start_prob = {}\n",
    "\n",
    "\n",
    "for each_state, each_value in start_state_dict.items():\n",
    "    start_prob[each_state] =  each_value / sum(start_state_dict.values())\n",
    "            \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "017f44da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(start_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1742193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate state transition dictionary.\n",
    "\n",
    "state_transition_dict = OrderedDict()\n",
    "\n",
    "for index in range(len(complete_data)-1):\n",
    "    if complete_data[index] == '':\n",
    "        continue\n",
    "    else:\n",
    "        if complete_data[index+1] != '':\n",
    "            state1 = complete_data[index].split('\\t')\n",
    "            state2 = complete_data[index+1].split('\\t')\n",
    "\n",
    "            key = str(state1[2]+\" , \"+state2[2])\n",
    "            state_transition_dict[key] = state_transition_dict.get(key, 0) + 1\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28cff8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition = {}\n",
    "\n",
    "for each_state, each_value in state_transition_dict.items():\n",
    "    transition[each_state] =  each_value / pos_tagging_dict[each_state.split(' , ')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "387fc36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b1c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_dict = OrderedDict()\n",
    "\n",
    "for index in range(len(complete_data)-1):\n",
    "    if complete_data[index] == '':\n",
    "        continue\n",
    "    else:\n",
    "        each_state = complete_data[index].split('\\t')\n",
    "        if each_state[1] not in word_vocab_ordered:\n",
    "            key =  each_state[2] + \" , <unk>\"\n",
    "            emission_dict[key] = emission_dict.get(key, 0) + 1\n",
    "        else:\n",
    "            key =  each_state[2] + \" , \" + each_state[1]\n",
    "            emission_dict[key] = emission_dict.get(key, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3082e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "emission = {}\n",
    "\n",
    "for each_state, each_value in emission_dict.items():\n",
    "    emission[each_state] =  each_value / pos_tagging_dict[each_state.split(' , ')[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a44aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30303"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37e5e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_result = '{ \\n \"transition\" : ' + json.dumps(transition) + ', \\n \"emission\" : ' + json.dumps(emission) + ', \\n \"start_prob\" : ' + json.dumps(start_prob) + \"\\n }\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed3d001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hmm.json\", \"w\") as text_file:\n",
    "    text_file.write(format(hmm_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef62f11",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa588e",
   "metadata": {},
   "source": [
    "``` Greedy Decoding in Hidden Markov Models ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91693b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = open(\"data/dev\", \"r\")\n",
    "dev_data = dev_data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d49beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = open(\"data/test\", \"r\")\n",
    "test_data = test_data.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fda0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decoding(observation, emission, transition, states, start_prob):\n",
    "\n",
    "    sequence = []\n",
    "\n",
    "    for i in range(len(observation)):\n",
    "        best_state = None\n",
    "        max_prob = float('-inf')\n",
    "\n",
    "        for st in states:\n",
    "            if i == 0:\n",
    "\n",
    "                if st in start_prob:\n",
    "                    if(st + \" , \" + observation[i]) in emission:\n",
    "                        cur_prob = start_prob[st] * emission[st + \" , \" + observation[i]]\n",
    "                    else:\n",
    "                        cur_prob = 0\n",
    "                else:\n",
    "                    cur_prob = 0\n",
    "\n",
    "                if cur_prob > max_prob:\n",
    "                    best_state = st\n",
    "\n",
    "                    max_prob = cur_prob\n",
    "            else:\n",
    "                if (st+\" , \"+observation[i]) in emission and (sequence[-1] +\" , \"+ st) in transition:\n",
    "                    cur_prob = transition[sequence[-1] +\" , \"+ st] * emission[st+\" , \"+observation[i]]\n",
    "                else:\n",
    "                    cur_prob = 0\n",
    "\n",
    "                if cur_prob > max_prob:\n",
    "                    max_prob = cur_prob\n",
    "                    best_state = st\n",
    "\n",
    "        sequence.append(best_state)\n",
    "        \n",
    "    return sequence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f8171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = []\n",
    "dev_result = []\n",
    "gtotal_dev_sequence = []\n",
    "states = list(pos_tagging_dict.keys())\n",
    "\n",
    "for obs in dev_data.split('\\n'):\n",
    "    if obs == \"\":\n",
    "        each_sequence = greedy_decoding(observation, emission, transition, states, start_prob)\n",
    "        gtotal_dev_sequence += each_sequence\n",
    "        observation = []\n",
    "        continue\n",
    "    \n",
    "    if obs.split('\\t')[1] not in word_vocab_ordered:\n",
    "        observation.append('<unk>')\n",
    "    else:\n",
    "        observation.append(obs.split('\\t')[1])\n",
    "    dev_result.append(obs.split('\\t')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffbc9f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9350297492562686"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dev_result, gtotal_dev_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68292fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = []\n",
    "gtotal_test_sequence = []\n",
    "states = list(pos_tagging_dict.keys())\n",
    "\n",
    "# Generate results for the test data.\n",
    "\n",
    "for obs in test_data.split('\\n'):\n",
    "    if obs == \"\":\n",
    "        each_sequence = greedy_decoding(observation, emission, transition, states, start_prob)\n",
    "        each_sequence.append(\"''\")\n",
    "        gtotal_test_sequence += each_sequence \n",
    "        observation = []\n",
    "        \n",
    "        continue\n",
    "    \n",
    "    if obs.split('\\t')[1] not in word_vocab_ordered:\n",
    "        observation.append('<unk>')\n",
    "    else:\n",
    "        observation.append(obs.split('\\t')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4b4d3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_complete = test_data.split('\\n')\n",
    "test_result_string = \"\"\n",
    "\n",
    "for i in range(len(test_data_complete)):\n",
    "    obs = test_data_complete[i].split('\\t')\n",
    "    if obs[0] != '':\n",
    "        test_result_string += obs[0]+'\\t'+obs[1]+'\\t'+gtotal_test_sequence[i]+'\\n'\n",
    "    else:\n",
    "        test_result_string+=\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de819578",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"greedy.out\", \"w\") as text_file:\n",
    "    text_file.write(format(test_result_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3a42b",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ff7e8e",
   "metadata": {},
   "source": [
    "``` Viterbi Decoding in Hidden Markov Models. ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddea383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decoding(observation, emission, transition, states, start_prob):\n",
    "    v_table = np.zeros((len(observation), len(states)), dtype = float)\n",
    "    b_table = np.zeros((len(observation), len(states)), dtype=int)\n",
    "    \n",
    "    idx_pos = {tag: idx for idx, tag in enumerate(states)}\n",
    "    pos_idx = {idx: tag for idx, tag in enumerate(states)}\n",
    "    \n",
    "    for st in range(len(states)):\n",
    "        state = states[st]\n",
    "        v_table[0, st] = start_prob.get(state, 0) * emission.get(state +\" , \"+observation[0] , 0) \n",
    "        b_table[0, st] = 0\n",
    "        \n",
    "\n",
    "    for i in range(1, len(observation)):\n",
    "        for cur_st in range(len(states)):\n",
    "            state = states[cur_st]\n",
    "            word = observation[i]\n",
    "            max_prob = 0\n",
    "            max_state = -1\n",
    "    \n",
    "            for prev_st in range(len(states)):\n",
    "                prev_state = states[prev_st]\n",
    "                if prev_state + ' , ' + state in transition and state+\" , \"+word in emission:\n",
    "                    cur_prob = v_table[i-1, prev_st] * transition[prev_state + ' , ' + state] * emission[state+\" , \"+word] \n",
    "                else:\n",
    "                    cur_prob = 0\n",
    "                \n",
    "                if cur_prob >= max_prob:\n",
    "                    max_prob = cur_prob\n",
    "                    max_state = prev_st\n",
    "                    \n",
    "            b_table[i, cur_st] = max_state\n",
    "            v_table[i, cur_st] = max_prob\n",
    "                            \n",
    "    best_sequence = []\n",
    "    last_state = np.argmax(v_table[len(observation)-1, :])\n",
    "    best_sequence.append(states[last_state])\n",
    "    \n",
    "    for j in range(len(observation) - 1, 0, -1):\n",
    "        last_state = b_table[j, last_state]\n",
    "        best_sequence.append(states[last_state])\n",
    "    \n",
    "    best_sequence.reverse()\n",
    "    return best_sequence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f63e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = []\n",
    "true_result = []\n",
    "vdev_total_sequence = []\n",
    "states = list(pos_tagging_dict.keys())\n",
    "\n",
    "for obs in dev_data.split('\\n'):\n",
    "    if obs == \"\":\n",
    "        each_sequence = viterbi_decoding(observation, emission, transition, states, start_prob)\n",
    "        vdev_total_sequence+=each_sequence\n",
    "        observation = []\n",
    "        continue\n",
    "    \n",
    "    if obs.split('\\t')[1] not in word_vocab_ordered:\n",
    "        observation.append('<unk>')\n",
    "    else:\n",
    "        observation.append(obs.split('\\t')[1])\n",
    "    true_result.append(obs.split('\\t')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e0d3cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473013174670634"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true_result, vdev_total_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e711dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = []\n",
    "viterbi_total_test_sequence = []\n",
    "states = list(pos_tagging_dict.keys())\n",
    "index = 1\n",
    "\n",
    "for obs in test_data.split('\\n'):\n",
    "    if obs == \"\":\n",
    "        each_sequence = viterbi_decoding(observation, emission, transition, states, start_prob)\n",
    "        each_sequence.append(\"''\")\n",
    "        viterbi_total_test_sequence += each_sequence \n",
    "        observation = []\n",
    "        continue\n",
    "    \n",
    "    if obs.split('\\t')[1] not in word_vocab_ordered:\n",
    "        observation.append('<unk>')\n",
    "    else:\n",
    "        observation.append(obs.split('\\t')[1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01a0dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_complete = test_data.split('\\n')\n",
    "vtest_result_string = \"\"\n",
    "\n",
    "for i in range(len(test_data_complete)):\n",
    "    obs = test_data_complete[i].split('\\t')\n",
    "    if obs[0] != '':\n",
    "        vtest_result_string += obs[0]+'\\t'+obs[1]+'\\t'+viterbi_total_test_sequence[i]+'\\n'\n",
    "    else:\n",
    "        vtest_result_string+=\"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2b75cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"viterbi.out\", \"w\") as text_file:\n",
    "    text_file.write(format(vtest_result_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301b6e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
